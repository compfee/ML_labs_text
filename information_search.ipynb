{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Используя в качестве документов тексты запросов из набора текстов об аэронавтике CRANFIELD (те же, что и в примере), найдите пару наиболее близких к указанному запросу документа."
      ],
      "metadata": {
        "id": "aXXUAz4LkUDS"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vd_ST0GfO97y"
      },
      "source": [
        "# Информационный поиск\n",
        "\n",
        "Скачиваем классический набор данных -- набор текстов об аэронавтике CRANFIELD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AHflLH2APAHK",
        "outputId": "404cbcaa-1d47-40e8-b94e-fbc52f13a6e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cran.all.1400\n",
            "cran.qry\n",
            "cranqrel\n",
            "cranqrel.readme\n"
          ]
        }
      ],
      "source": [
        "! wget -q http://ir.dcs.gla.ac.uk/resources/test_collections/cran/cran.tar.gz\n",
        "! tar -xvf cran.tar.gz\n",
        "! rm cran.tar.gz*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zYuND83cPR5D"
      },
      "source": [
        "Берём только сами запросы (это будут наши документы)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6owW-L7zhJws",
        "outputId": "a5b2a8a0-6c06-472b-c6f1-e381a9deece1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "what similarity laws must be obeyed when constructing aeroelastic models\r\n",
            "of heated high speed aircraft .\r\n",
            "what are the structural and aeroelastic problems associated with flight\r\n"
          ]
        }
      ],
      "source": [
        "! grep -v \"^\\.\" cran.qry > just.qry\n",
        "! head -3 just.qry"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ZbUb6FmQxr1"
      },
      "source": [
        "Объединяем многострочные в один"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SBaV3xeQiUam",
        "outputId": "34c63b08-97ec-46c9-e9f0-0501142e110e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['what similarity laws must be obeyed when constructing aeroelastic models of heated high speed aircraft . ',\n",
              " 'what are the structural and aeroelastic problems associated with flight of high speed aircraft . ']"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "raw_query_data = [line.strip() for line in open(\"just.qry\", \"r\").readlines()]\n",
        "query_data = [\"\"]\n",
        "\n",
        "for query_part in raw_query_data:\n",
        "  query_data[-1] += query_part + \" \"\n",
        "  if query_part.endswith(\".\"):\n",
        "    query_data.append(\"\")\n",
        "\n",
        "query_data[:2] #Выведем пару документов для примера"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nLFq_6lBki3S"
      },
      "source": [
        "### Составим запросы к нашим документам"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h3sgHjWkjjR1"
      },
      "outputs": [],
      "source": [
        "QUERIES = ['viscous interactions']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hQMdH0HSkoJg"
      },
      "source": [
        "## Boolean retrieval\n",
        "Представим каждый документ как \"битовую маску\": вектор размером со словарь, в котором на каждой позиции единица, если в документе есть соответсвующий терм, и ноль, если терма нет"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lhrI18rZSLLz",
        "outputId": "a53fa79f-46fe-4d05-b5c3-5517e2962489"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for scikit-learn (setup.py) ... \u001b[?25l\u001b[?25hcanceled\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "! pip install -q scikit-learn==0.22.2.post1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DbTOdsHIknD0",
        "outputId": "c3445b80-698e-4bd4-f790-3361b73e7ab5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['what', 'similarity', 'laws']"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "from  sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "encoder = CountVectorizer(binary=True)\n",
        "encoded_data = encoder.fit_transform(query_data)\n",
        "encoded_queries = encoder.transform(QUERIES)\n",
        "list(encoder.vocabulary_)[:3]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oUdwKDKSTjdD"
      },
      "source": [
        "Посмотрим на представление первого предложения"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oXEmXErylJdX",
        "outputId": "918cc14f-a424-4d65-d758-dc5c035c8f8c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['what',\n",
              " 'similarity',\n",
              " 'laws',\n",
              " 'must',\n",
              " 'be',\n",
              " 'obeyed',\n",
              " 'when',\n",
              " 'constructing',\n",
              " 'aeroelastic',\n",
              " 'models',\n",
              " 'of',\n",
              " 'heated',\n",
              " 'high',\n",
              " 'speed',\n",
              " 'aircraft']"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "id2term = {idx: term for term, idx in encoder.vocabulary_.items()}\n",
        "non_zero_values_ids = encoded_data[0].nonzero()[1]\n",
        "\n",
        "terms = [id2term[idx] for idx in non_zero_values_ids]\n",
        "terms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8wdS9XiVwb2"
      },
      "source": [
        "\n",
        "## Задание 0\n",
        "\n",
        "Теперь для каждого из данных запросов `QUERIES` найдём ближайший для него документ из `query_data` по сходству Жаккара. Есть более эффективные способы это сделать, но вам требуется реализовать расстояние Жаккара и далее применить его к нашим данным."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u31WuBYAUWt2",
        "outputId": "5778adb9-4987-4e41-c83b-8b8b4e23cd85"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.027777777777777776, 0.02857142857142857, 0.03225806451612903, 0.03333333333333333, 0.03333333333333333, 0.03333333333333333, 0.034482758620689655, 0.03571428571428571, 0.037037037037037035, 0.037037037037037035, 0.038461538461538464, 0.04, 0.04, 0.04, 0.041666666666666664, 0.041666666666666664, 0.041666666666666664, 0.041666666666666664, 0.041666666666666664, 0.041666666666666664, 0.041666666666666664, 0.041666666666666664, 0.041666666666666664, 0.043478260869565216, 0.043478260869565216, 0.043478260869565216, 0.043478260869565216, 0.043478260869565216, 0.043478260869565216, 0.043478260869565216, 0.045454545454545456, 0.045454545454545456, 0.045454545454545456, 0.045454545454545456, 0.045454545454545456, 0.045454545454545456, 0.045454545454545456, 0.045454545454545456, 0.045454545454545456, 0.047619047619047616, 0.047619047619047616, 0.047619047619047616, 0.047619047619047616, 0.047619047619047616, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05263157894736842, 0.05263157894736842, 0.05263157894736842, 0.05263157894736842, 0.05263157894736842, 0.05263157894736842, 0.05263157894736842, 0.05263157894736842, 0.05263157894736842, 0.05263157894736842, 0.05263157894736842, 0.05263157894736842, 0.05555555555555555, 0.05555555555555555, 0.05555555555555555, 0.05555555555555555, 0.05555555555555555, 0.05555555555555555, 0.05555555555555555, 0.05555555555555555, 0.05555555555555555, 0.05555555555555555, 0.058823529411764705, 0.058823529411764705, 0.058823529411764705, 0.058823529411764705, 0.058823529411764705, 0.058823529411764705, 0.058823529411764705, 0.058823529411764705, 0.058823529411764705, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.06666666666666667, 0.06666666666666667, 0.06666666666666667, 0.06666666666666667, 0.06666666666666667, 0.06666666666666667, 0.06666666666666667, 0.06666666666666667, 0.06666666666666667, 0.06666666666666667, 0.06666666666666667, 0.06666666666666667, 0.06666666666666667, 0.07142857142857142, 0.07142857142857142, 0.07142857142857142, 0.08333333333333333, 0.08333333333333333, 0.08333333333333333, 0.08333333333333333, 0.08333333333333333, 0.08333333333333333, 0.08333333333333333, 0.09090909090909091, 0.09090909090909091, 0.09090909090909091, 0.09090909090909091, 0.09090909090909091, 0.09090909090909091, 0.09090909090909091, 0.09090909090909091, 0.1, 0.1111111111111111, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.2]\n",
            "0.14285714285714285\n",
            "14\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "def jaccard_sim(vector_a: np.array, vector_b: np.array) -> float:\n",
        "  \"\"\"\n",
        "    Сходство или коэффициент Жаккара: отношение мощности пересечения\n",
        "    к мощности объединения\n",
        "  \"\"\"\n",
        "  intersection = np.logical_and(vector_a,vector_b)\n",
        "  union = np.logical_or(vector_a,vector_b)\n",
        "  J = intersection.sum() / float(union.sum())\n",
        "  return J\n",
        "\n",
        "#Проверка, что функция работает правильно\n",
        "# assert jaccard_similarity(np.array([1, 0, 1, 0, 1]), np.array([0, 1, 1, 1, 1])) == 0.4\n",
        "# print(str(query_data[0]).split())\n",
        "\n",
        "# def jac(x: set, y: set):\n",
        "#   x = set(str(x).split())\n",
        "#   y = set(str(y).split())\n",
        "#   shared = x.intersection(y)  # selects shared tokens only\n",
        "#   return len(shared) / len(x.union(y))  # union adds both sets together\n",
        "\n",
        "m=[]\n",
        "index = []\n",
        "for q in range(len(query_data)):\n",
        "  m.append(jaccard_sim(encoded_queries.toarray(), encoded_data[q].toarray()))\n",
        "\n",
        "m_ = m.copy()\n",
        "m_.sort()\n",
        "print(m_)\n",
        "print(m_[len(m_)-2])\n",
        "print(m.index(m_[len(m_)-2]))\n",
        "\n",
        "# print(m)\n",
        "# print(max(m))\n",
        "# print(m.index(max(m)))\n",
        "# max_index\n",
        "# # m = []\n",
        "# # for q in query_data:\n",
        "# #   print(q)\n",
        "# #   print(QUERIES[0])\n",
        "# #   m.append(jaccard_sim(QUERIES[0], q))\n",
        "# # max(m)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dYfQksWrOR1G"
      },
      "source": [
        "## Задание 1\n",
        "Теперь с помощью кода ниже вычислите для каждого запроса самые близкие документы."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4okpFpA6OAQs",
        "outputId": "a2a3a869-7143-43d0-906a-a03ff47c711b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q: range of enthalpies\n",
            "FOUND:\n",
            "    9\t0.20\tare real-gas transport properties for air available over a wide range of enthalpies and densities . \n",
            "    14\t0.14\tmaterial properties of photoelastic materials . \n",
            "    132\t0.14\ttheoretical studies of creep buckling . \n"
          ]
        }
      ],
      "source": [
        "for q_id, query in enumerate(encoded_queries):\n",
        "  # приводим к нужному типу\n",
        "  query = query.todense().A1\n",
        "  docs = [doc.todense().A1 for doc in encoded_data]\n",
        "  # вычисляем коэфф. Жаккара\n",
        "  id2doc2similarity = [(doc_id, doc, jaccard_sim(query, doc)) for doc_id, doc in enumerate(docs)]\n",
        "  # сортируем по нему\n",
        "  closest = sorted(id2doc2similarity, key=lambda x: x[2], reverse=True)\n",
        "\n",
        "  print(\"Q: %s\\nFOUND:\" % QUERIES[q_id])\n",
        "  # выводим по 3 наиболее близких документа для каждого запроса\n",
        "  for closest_id, _, sim in closest[:3]:\n",
        "    print(\"    %d\\t%.2f\\t%s\" %(closest_id, sim, query_data[closest_id]))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A1Fh8RdvOrAD"
      },
      "source": [
        "Видим, что кое-где просачиваются  тексты, которых с запросами объединяют малозначительные термы, но при этом коэффициент Жаккара -- наша функция ранжирования! -- высок.\n",
        "\n",
        "# VSM\n",
        "\n",
        "Попробуем теперь сделать то же, но с tf-idf и косинусным расстоянием. Мы сделаем всё опять \"руками\", но \"в реальной жизни\" лучше использоватьесть эффективные реализации cosine distance, например, из библиотеки scipy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DmpKMI08E2iO",
        "outputId": "118fb39c-81fe-4669-c385-62adaf758d4f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['what', 'similarity', 'laws']"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ],
      "source": [
        "from  sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Совет: обязательно разберитесь с тем, какие возможности\n",
        "# предоставляет tf-idf vectorizer, какие параметры за что отвечают\n",
        "\n",
        "tfidf_encoder = TfidfVectorizer()\n",
        "tfidf_encoded_data = tfidf_encoder.fit_transform(query_data)\n",
        "tfidf_encoded_queries = tfidf_encoder.transform(QUERIES)\n",
        "\n",
        "list(tfidf_encoder.vocabulary_)[:3]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hHTzIjfNRHj2"
      },
      "source": [
        "## Задание 2\n",
        "Реализовать косинусное расстояние"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UCfgR6xEPeDn"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def cosine_distance(vector_a: np.array, vector_b: np.array) -> float:\n",
        "  \"\"\"\n",
        "    Косинусное расстояние: единица минус отношение скалярного произведения\n",
        "    на произведение L2-норм (подсказка: в numpy такие нормы есть)\n",
        "  \"\"\"\n",
        "  dot_product = np.dot(vector_a, vector_b)\n",
        "  norm_v1 = np.linalg.norm(vector_a)\n",
        "  norm_v2 = np.linalg.norm(vector_b)\n",
        "  cosine_similarity = dot_product / (norm_v1 * norm_v2)\n",
        "\n",
        "  # calculate cosine distance\n",
        "  cosine_distance = 1 - cosine_similarity\n",
        "\n",
        "  return cosine_distance\n",
        "#Проверка, что функция работает правильно\n",
        "assert cosine_distance(np.array([1, 0, 1, 1, 1]), np.array([0, 0, 1, 0, 0])) == 0.5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vJHsaHoORlEC"
      },
      "source": [
        "\n",
        "Теперь вычислим ближайшие по косинусному расстоянию между векторными представлениями документов и запросов"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fIZJRBKQQR1G",
        "outputId": "c5114440-3134-46dc-ef5e-30eba68f10d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q: viscous interactions\n",
            "FOUND:\n",
            "    44\t0.50\thas anyone investigated the effect of surface mass transfer on hypersonic viscous interactions . \n",
            "    46\t0.56\twhat are the existing solutions for hypersonic viscous interactions over an insulated flat plate . \n",
            "    71\t0.64\twhat has been done about viscous interactions in relatively low reynolds number flows,  particularly at high mach numbers . \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-103-030d78230e6b>:11: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  cosine_similarity = dot_product / (norm_v1 * norm_v2)\n"
          ]
        }
      ],
      "source": [
        "for q_id, query in enumerate(tfidf_encoded_queries):\n",
        "\n",
        "  # приводим к нужному типу\n",
        "  query = query.todense().A1\n",
        "  docs = [doc.todense().A1 for doc in tfidf_encoded_data]\n",
        "  # Косинусное расстояние\n",
        "  id2doc2similarity = [(doc_id, doc, cosine_distance(query, doc)) \\\n",
        "                       for doc_id, doc in enumerate(docs)]\n",
        "  # сортируем по нему\n",
        "  closest = sorted(id2doc2similarity, key=lambda x: x[2], reverse=False)\n",
        "\n",
        "  print(\"Q: %s\\nFOUND:\" % QUERIES[q_id])\n",
        "\n",
        "  for closest_id, _, sim in closest[:3]:\n",
        "    print(\"    %d\\t%.2f\\t%s\" %(closest_id, sim, query_data[closest_id]))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}